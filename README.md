# Awesome In-Context DiT

[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com)

A curated list of research papers that leverage in-context learning techniques in Diffusion Transformers (DiT) for various downstream tasks.

## Contents

- [Introduction](#introduction)
- [Papers](#papers)
- [Contributing](#contributing)
- [License](#license)

## Introduction

Diffusion Transformers (DiT) have emerged as powerful models for generative tasks, combining the strengths of diffusion models with transformer architectures. In-context learning techniques allow these models to adapt to new tasks without parameter updates by conditioning on relevant examples or prompts.

This repository aims to collect and organize research exploring in-context learning capabilities within DiT models across various downstream applications.

## Papers

- **In-Context LoRA for Diffusion Transformers** (Arxiv 2024) [[Paper](https://arxiv.org/abs/2504.02160)] [[Code](https://github.com/ali-vilab/In-Context-LoRA)] [[Project Page](https://ali-vilab.github.io/In-Context-LoRA-Page)]  
  *Lianghua Huang, Wei Wang, Zhi-Fan Wu, Yupeng Shi, Huanzhang Dou, Chen Liang, Yutong Feng, Yu Liu, Jingren Zhou*
  
- **OminiControl: Minimal and Universal Control for Diffusion Transformer** (Arxiv 2024) [[Paper](https://arxiv.org/abs/2504.02160)] [[Code](https://github.com/Yuanshi9815/OminiControl)]  
  *Zhenxiong Tan, Songhua Liu, Xingyi Yang, Qiaochu Xue, and Xinchao Wang*
  
- **EasyControl: Adding Efficient and Flexible Control for Diffusion Transformer** (Arxiv 2024) [[Paper](https://arxiv.org/pdf/2503.07027)] [[Code](https://github.com/Xiaojiu-z/EasyControl)] [[Project Page](https://easycontrolproj.github.io/)]  
  *Yuxuan Zhang, Yirui Yuan, Yiren Song, Haofan Wang, Jiaming Liu*

- **UNO: A Universal Customization Method for Both Single and Multi-Subject Conditioning** (Arxiv 2024) [[Paper](https://arxiv.org/abs/2504.02160)] [[Code](https://github.com/bytedance/UNO)] [[Project Page](https://bytedance.github.io/UNO/)]  
  *Shaojin Wu, Mengqi Huang*, Wenxu Wu, Yufeng Cheng, Fei Ding+, Qian He*
  

## Contributing

We welcome contributions! Please feel free to submit a PR to add new papers or resources.

**Guidelines for adding papers:**
1. Ensure the paper uses in-context learning techniques with DiT models
2. Follow the established format for paper entries
3. Place the paper in the appropriate category
4. Provide links to paper, code, and project page when available

## License

MIT License
